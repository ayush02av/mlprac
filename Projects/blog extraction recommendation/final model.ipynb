{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0da3f7",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d450a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76740e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c8c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I donÃ¢ÂÂt remember his name, but I remem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI!!!    I was sitting in the police sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              topic  \\\n",
       "0           0            Student   \n",
       "1           1  InvestmentBanking   \n",
       "2           2          Education   \n",
       "3           3            Science   \n",
       "4           4            Student   \n",
       "\n",
       "                                                text  \n",
       "0  In het kader van kernfusie op aarde:  MAAK JE ...  \n",
       "1  Just so you know, this blog isn't about being ...  \n",
       "2  I  I donÃ¢ÂÂt remember his name, but I remem...  \n",
       "3  so there they were in the cotton candy shack. ...  \n",
       "4  By: TIRI!!!    I was sitting in the police sta...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3f2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f89d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['index', 'topic', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9513fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I donÃ¢ÂÂt remember his name, but I remem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI!!!    I was sitting in the police sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic                                               text\n",
       "0      0            Student  In het kader van kernfusie op aarde:  MAAK JE ...\n",
       "1      1  InvestmentBanking  Just so you know, this blog isn't about being ...\n",
       "2      2          Education  I  I donÃ¢ÂÂt remember his name, but I remem...\n",
       "3      3            Science  so there they were in the cotton candy shack. ...\n",
       "4      4            Student  By: TIRI!!!    I was sitting in the police sta..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f366b5e",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57355a9e",
   "metadata": {},
   "source": [
    "### Removing unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936ea6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ã¢Â\\x80Â\\x9cIÃ¢Â\\x80Â\\x99m sorry, what?Ã¢Â\\x80Â\\x9d I mumbled as I looked up, meeting eyes with my waitress. IÃ¢Â\\x80Â\\x99m not entirely sure how long she had been standing there or how many times she had asked her question. Ã¢Â\\x80Â\\x9cOh um, right. Could I get a mocha?Ã¢Â\\x80Â\\x9d  Ã¢Â\\x80Â\\x9cSure thing, Hon. No problem,Ã¢Â\\x80Â\\x9d she replied in a motherly voice as she turned to head back to the counter.  Ã¢Â\\x80Â\\x9cOh, and a little extra chocolate, please!Ã¢Â\\x80Â\\x9d I called after her. It wasnÃ¢Â\\x80Â\\x99t that I was a chocolate freak. I just had to cover up the bite of the espresso. Too much of that, and my stomach was done.  The cafÃ\\x83Â© was quaint and quiet. But then again, how much business can you expect on a Wednesday night? Sure, there was the troubled Goth in the corner, the terribly hip guy strumming his guitar in the other corner, and a pair of half-dressed, bleach-blonde creatures I can only describe as Ã¢Â\\x80Â\\x9cGigglyÃ¢Â\\x80Â\\x9d sitting a few tables to my right. And then there was me. What the hell was I doing here? Ah well, the chair was comfortable enough, and I was well on my way to some mocha-filled solitudeÃ¢Â\\x80Â¦  She must have been hiding elsewhere, around some corner or in some other nook out of my sight, because I certainly didnÃ¢Â\\x80Â\\x99t hear any door bell jingling to announce her entrance. Yet there she was, walking toward me of all people, with that casual yet alluring swing to her hips. It was useless to avoid eye contact. She knew I saw her, and it put a warm smile on her lips, a smile at which I couldnÃ¢Â\\x80Â\\x99t resist s'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[50][:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8263cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.text.replace('[^a-zA-Z.,?: /\\\\\\'\\\"]', '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f447b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im sorry, what? I mumbled as I looked up, meeting eyes with my waitress. Im not entirely sure how long she had been standing there or how many times she had asked her question. Oh um, right. Could I get a mocha?  Sure thing, Hon. No problem, she replied in a motherly voice as she turned to head back to the counter.  Oh, and a little extra chocolate, please I called after her. It wasnt that I was a chocolate freak. I just had to cover up the bite of the espresso. Too much of that, and my stomach was done.  The caf was quaint and quiet. But then again, how much business can you expect on a Wednesday night? Sure, there was the troubled Goth in the corner, the terribly hip guy strumming his guitar in the other corner, and a pair of halfdressed, bleachblonde creatures I can only describe as Giggly sitting a few tables to my right. And then there was me. What the hell was I doing here? Ah well, the chair was comfortable enough, and I was well on my way to some mochafilled solitude  She must have been hiding elsewhere, around some corner or in some other nook out of my sight, because I certainly didnt hear any door bell jingling to announce her entrance. Yet there she was, walking toward me of all people, with that casual yet alluring swing to her hips. It was useless to avoid eye contact. She knew I saw her, and it put a warm smile on her lips, a smile at which I couldnt resist staring. My mouth was probably open.  You look surprised to see me, she said, but her voice was so delica'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[50][:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e875ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I dont remember his name, but I remember th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI    I was sitting in the police statio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic                                               text\n",
       "0      0            Student  In het kader van kernfusie op aarde:  MAAK JE ...\n",
       "1      1  InvestmentBanking  Just so you know, this blog isn't about being ...\n",
       "2      2          Education  I  I dont remember his name, but I remember th...\n",
       "3      3            Science  so there they were in the cotton candy shack. ...\n",
       "4      4            Student  By: TIRI    I was sitting in the police statio..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213c390",
   "metadata": {},
   "source": [
    "### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf93c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set = set( stopwords.words('english') + stopwords.words('spanish') + stopwords.words('dutch') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86bb210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['la', 'zal', 'para', \"it's\", 'does']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stopwords_set)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061b5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\",*(\\s*\\b(?:{}))\\b\".format(\"|\".join(stopwords_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5002289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_remove_stopwords(text):\n",
    "    text = re.sub('[^a-zA-Z,.? ]', '', text)\n",
    "    return re.sub(pattern, \"\", text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e802ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['details'] = df.text.apply(df_remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "169eb3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "      <td>In kader kernfusie aarde  MAAK JE EIGEN WATERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "      <td>Just know blog isnt political. If anything apo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I dont remember his name, but I remember th...</td>\n",
       "      <td>I  I dont remember name I remember first time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "      <td>cotton candy shack. bo jangles, mr.johnreed, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI    I was sitting in the police statio...</td>\n",
       "      <td>By TIRI    I sitting police station someone ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic  \\\n",
       "0      0            Student   \n",
       "1      1  InvestmentBanking   \n",
       "2      2          Education   \n",
       "3      3            Science   \n",
       "4      4            Student   \n",
       "\n",
       "                                                text  \\\n",
       "0  In het kader van kernfusie op aarde:  MAAK JE ...   \n",
       "1  Just so you know, this blog isn't about being ...   \n",
       "2  I  I dont remember his name, but I remember th...   \n",
       "3  so there they were in the cotton candy shack. ...   \n",
       "4  By: TIRI    I was sitting in the police statio...   \n",
       "\n",
       "                                             details  \n",
       "0  In kader kernfusie aarde  MAAK JE EIGEN WATERS...  \n",
       "1  Just know blog isnt political. If anything apo...  \n",
       "2  I  I dont remember name I remember first time ...  \n",
       "3  cotton candy shack. bo jangles, mr.johnreed, c...  \n",
       "4  By TIRI    I sitting police station someone ca...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c1f72",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe04a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sent_tokenize(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17ccef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['details'] = df.details.apply(df_sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f3c40fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "      <td>[In kader kernfusie aarde  MAAK JE EIGEN WATER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "      <td>[Just know blog isnt political., If anything a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I dont remember his name, but I remember th...</td>\n",
       "      <td>[I  I dont remember name I remember first time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "      <td>[cotton candy shack., bo jangles, mr.johnreed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI    I was sitting in the police statio...</td>\n",
       "      <td>[By TIRI    I sitting police station someone c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic  \\\n",
       "0      0            Student   \n",
       "1      1  InvestmentBanking   \n",
       "2      2          Education   \n",
       "3      3            Science   \n",
       "4      4            Student   \n",
       "\n",
       "                                                text  \\\n",
       "0  In het kader van kernfusie op aarde:  MAAK JE ...   \n",
       "1  Just so you know, this blog isn't about being ...   \n",
       "2  I  I dont remember his name, but I remember th...   \n",
       "3  so there they were in the cotton candy shack. ...   \n",
       "4  By: TIRI    I was sitting in the police statio...   \n",
       "\n",
       "                                             details  \n",
       "0  [In kader kernfusie aarde  MAAK JE EIGEN WATER...  \n",
       "1  [Just know blog isnt political., If anything a...  \n",
       "2  [I  I dont remember name I remember first time...  \n",
       "3  [cotton candy shack., bo jangles, mr.johnreed,...  \n",
       "4  [By TIRI    I sitting police station someone c...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a122e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_word_tokenize(sentences):\n",
    "    return [\n",
    "        word_tokenize(sentence)\n",
    "        for sentence in sentences\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f754ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['details'] = df.details.apply(df_word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "489f1d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "      <td>[[In, kader, kernfusie, aarde, MAAK, JE, EIGEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "      <td>[[Just, know, blog, isnt, political, .], [If, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I dont remember his name, but I remember th...</td>\n",
       "      <td>[[I, I, dont, remember, name, I, remember, fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "      <td>[[cotton, candy, shack, .], [bo, jangles, ,, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI    I was sitting in the police statio...</td>\n",
       "      <td>[[By, TIRI, I, sitting, police, station, someo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic  \\\n",
       "0      0            Student   \n",
       "1      1  InvestmentBanking   \n",
       "2      2          Education   \n",
       "3      3            Science   \n",
       "4      4            Student   \n",
       "\n",
       "                                                text  \\\n",
       "0  In het kader van kernfusie op aarde:  MAAK JE ...   \n",
       "1  Just so you know, this blog isn't about being ...   \n",
       "2  I  I dont remember his name, but I remember th...   \n",
       "3  so there they were in the cotton candy shack. ...   \n",
       "4  By: TIRI    I was sitting in the police statio...   \n",
       "\n",
       "                                             details  \n",
       "0  [[In, kader, kernfusie, aarde, MAAK, JE, EIGEN...  \n",
       "1  [[Just, know, blog, isnt, political, .], [If, ...  \n",
       "2  [[I, I, dont, remember, name, I, remember, fir...  \n",
       "3  [[cotton, candy, shack, .], [bo, jangles, ,, m...  \n",
       "4  [[By, TIRI, I, sitting, police, station, someo...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c14078",
   "metadata": {},
   "source": [
    "# Extracting title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bc496b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_extract_title(details):\n",
    "    try:\n",
    "        doc = [\n",
    "            TaggedDocument(words, [index])\n",
    "            for index, words in enumerate(details)\n",
    "        ]\n",
    "\n",
    "        model = Doc2Vec(epochs = 30)\n",
    "        model.build_vocab(doc)\n",
    "        model.train(doc, total_examples = model.corpus_count, epochs = model.epochs)\n",
    "        \n",
    "        counts = dict()\n",
    "        for word in model.wv.key_to_index:\n",
    "            counts[word] = model.wv.get_vecattr(word, 'count')\n",
    "        \n",
    "        counts = sorted(\n",
    "            counts.items(),\n",
    "            key = lambda item: item[1],\n",
    "            reverse = True\n",
    "        )[0:len(model.wv.index_to_key) // 2]\n",
    "        \n",
    "        counts = list(dict(counts).keys())\n",
    "        \n",
    "        negative_check = ['I', '?', '.' ,'he', 'him', 'she', 'her']\n",
    "        negative = list()\n",
    "        for neg in negative_check:\n",
    "            if neg in model.wv.index_to_key:\n",
    "                negative.append(neg)\n",
    "        \n",
    "        most_common = model.wv.most_similar(positive = counts, negative = negative)\n",
    "        title = ' '.join([word[0] for word in most_common])\n",
    "        \n",
    "        return title\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5a19e0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'take book Dame place along one read Paris banks Tower'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extract_title(df.details[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "62f1efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you must first build vocabulary before training the model\n",
      "you must first build vocabulary before training the model\n",
      "you must first build vocabulary before training the model\n",
      "you must first build vocabulary before training the model\n"
     ]
    }
   ],
   "source": [
    "df['title'] = df.details.apply(df_extract_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a15b5f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>details</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "      <td>[[In, kader, kernfusie, aarde, MAAK, JE, EIGEN...</td>\n",
       "      <td>nucleus enough Now percent When form In Your N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "      <td>[[Just, know, blog, isnt, political, .], [If, ...</td>\n",
       "      <td>Bush North make much didnt may Iraq country Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I dont remember his name, but I remember th...</td>\n",
       "      <td>[[I, I, dont, remember, name, I, remember, fir...</td>\n",
       "      <td>Im job say We could work knew education teachi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "      <td>[[cotton, candy, shack, .], [bo, jangles, ,, m...</td>\n",
       "      <td>else still little would make nbspnbsp jeepers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI    I was sitting in the police statio...</td>\n",
       "      <td>[[By, TIRI, I, sitting, police, station, someo...</td>\n",
       "      <td>talking deal murder roses saying home know goi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic  \\\n",
       "0      0            Student   \n",
       "1      1  InvestmentBanking   \n",
       "2      2          Education   \n",
       "3      3            Science   \n",
       "4      4            Student   \n",
       "\n",
       "                                                text  \\\n",
       "0  In het kader van kernfusie op aarde:  MAAK JE ...   \n",
       "1  Just so you know, this blog isn't about being ...   \n",
       "2  I  I dont remember his name, but I remember th...   \n",
       "3  so there they were in the cotton candy shack. ...   \n",
       "4  By: TIRI    I was sitting in the police statio...   \n",
       "\n",
       "                                             details  \\\n",
       "0  [[In, kader, kernfusie, aarde, MAAK, JE, EIGEN...   \n",
       "1  [[Just, know, blog, isnt, political, .], [If, ...   \n",
       "2  [[I, I, dont, remember, name, I, remember, fir...   \n",
       "3  [[cotton, candy, shack, .], [bo, jangles, ,, m...   \n",
       "4  [[By, TIRI, I, sitting, police, station, someo...   \n",
       "\n",
       "                                               title  \n",
       "0  nucleus enough Now percent When form In Your N...  \n",
       "1  Bush North make much didnt may Iraq country Pr...  \n",
       "2  Im job say We could work knew education teachi...  \n",
       "3  else still little would make nbspnbsp jeepers ...  \n",
       "4  talking deal murder roses saying home know goi...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac86843",
   "metadata": {},
   "source": [
    "# Recommending by Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5674d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['details'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c889cb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2016fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "017ac9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "topic    0\n",
       "text     0\n",
       "title    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1fd7ed08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "      <td>nucleus enough Now percent When form In Your N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "      <td>Bush North make much didnt may Iraq country Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I dont remember his name, but I remember th...</td>\n",
       "      <td>Im job say We could work knew education teachi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "      <td>else still little would make nbspnbsp jeepers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI    I was sitting in the police statio...</td>\n",
       "      <td>talking deal murder roses saying home know goi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic  \\\n",
       "0      0            Student   \n",
       "1      1  InvestmentBanking   \n",
       "2      2          Education   \n",
       "3      3            Science   \n",
       "4      4            Student   \n",
       "\n",
       "                                                text  \\\n",
       "0  In het kader van kernfusie op aarde:  MAAK JE ...   \n",
       "1  Just so you know, this blog isn't about being ...   \n",
       "2  I  I dont remember his name, but I remember th...   \n",
       "3  so there they were in the cotton candy shack. ...   \n",
       "4  By: TIRI    I was sitting in the police statio...   \n",
       "\n",
       "                                               title  \n",
       "0  nucleus enough Now percent When form In Your N...  \n",
       "1  Bush North make much didnt may Iraq country Pr...  \n",
       "2  Im job say We could work knew education teachi...  \n",
       "3  else still little would make nbspnbsp jeepers ...  \n",
       "4  talking deal murder roses saying home know goi...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "092576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_tag_row_title(row):\n",
    "    try:\n",
    "        return TaggedDocument(\n",
    "            word_tokenize(row['title']),\n",
    "            [row['index'], row['topic']]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9126521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['details'] = df.apply(df_tag_row_title, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4d7098aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE ...</td>\n",
       "      <td>nucleus enough Now percent When form In Your N...</td>\n",
       "      <td>([nucleus, enough, Now, percent, When, form, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Just so you know, this blog isn't about being ...</td>\n",
       "      <td>Bush North make much didnt may Iraq country Pr...</td>\n",
       "      <td>([Bush, North, make, much, didnt, may, Iraq, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>I  I dont remember his name, but I remember th...</td>\n",
       "      <td>Im job say We could work knew education teachi...</td>\n",
       "      <td>([Im, job, say, We, could, work, knew, educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Science</td>\n",
       "      <td>so there they were in the cotton candy shack. ...</td>\n",
       "      <td>else still little would make nbspnbsp jeepers ...</td>\n",
       "      <td>([else, still, little, would, make, nbspnbsp, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>By: TIRI    I was sitting in the police statio...</td>\n",
       "      <td>talking deal murder roses saying home know goi...</td>\n",
       "      <td>([talking, deal, murder, roses, saying, home, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              topic  \\\n",
       "0      0            Student   \n",
       "1      1  InvestmentBanking   \n",
       "2      2          Education   \n",
       "3      3            Science   \n",
       "4      4            Student   \n",
       "\n",
       "                                                text  \\\n",
       "0  In het kader van kernfusie op aarde:  MAAK JE ...   \n",
       "1  Just so you know, this blog isn't about being ...   \n",
       "2  I  I dont remember his name, but I remember th...   \n",
       "3  so there they were in the cotton candy shack. ...   \n",
       "4  By: TIRI    I was sitting in the police statio...   \n",
       "\n",
       "                                               title  \\\n",
       "0  nucleus enough Now percent When form In Your N...   \n",
       "1  Bush North make much didnt may Iraq country Pr...   \n",
       "2  Im job say We could work knew education teachi...   \n",
       "3  else still little would make nbspnbsp jeepers ...   \n",
       "4  talking deal murder roses saying home know goi...   \n",
       "\n",
       "                                             details  \n",
       "0  ([nucleus, enough, Now, percent, When, form, I...  \n",
       "1  ([Bush, North, make, much, didnt, may, Iraq, c...  \n",
       "2  ([Im, job, say, We, could, work, knew, educati...  \n",
       "3  ([else, still, little, would, make, nbspnbsp, ...  \n",
       "4  ([talking, deal, murder, roses, saying, home, ...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cbe31bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "da18a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(df.details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "96472518",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(df.details, total_examples = model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0c0802b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South father board There point following Dan police gave mind \n",
      "board mouth mind woman South happened police father Dan heart \n",
      "town weapons technology number blood means child upon Now near \n",
      "woman happened mouth slowly young upon body round police theres \n",
      "mind lived South quite police board headed mouth others Dan \n",
      "South father upon wife ones sent taking gave woman body \n",
      "taking upon wife ones sent father body gave South states \n",
      "child number town technology means blood weapons upon individual states \n",
      "upon wife taking gave near sent South town ones students \n",
      "number weapons technology town blood means child upon states male \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    words = model.wv.most_similar(model.infer_vector(word_tokenize('violent means to destroy the organization')), topn = 10 )\n",
    "    for word in words:\n",
    "        print(word[0], end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "7af6651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(df, model, sentence):\n",
    "    words = model.wv.most_similar(model.infer_vector(word_tokenize(sentence)), topn = 10 )\n",
    "    \n",
    "    results = set()\n",
    "    for word in words:\n",
    "        results.update(list(df[df['title'].str.contains(word[0])]['title']))\n",
    "        \n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a060afb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What vehicles repeat even might significant drive suggest case given',\n",
       " 'question Honor see one asked never practical What Malcolm El',\n",
       " '.... ... mom seen What time They one take home',\n",
       " 'health What needs Develop barriers women Prevention nbspnbsp among nbspnbspnbspnbspnbspnbspnbspnbsp',\n",
       " 'Ashlee hit Kassie D fell go people since started sat',\n",
       " 'right away things Indians didnt since found social last job',\n",
       " 'communicate A may every nodes wired When IP protocol information',\n",
       " 'formation tell black make duty use front used officer My',\n",
       " 'registration completed Certificate tax company establishment Registration government may Representative',\n",
       " 'Subjects Testimony Womens Shattered Henke Suzette LifeWriting Recovery scriptotherapy understand',\n",
       " 'know , Whats Had done love day .... youve time',\n",
       " 'Vaughan Logan ... The may Storm know uniform music dont',\n",
       " 'Had thing one done stars youve em depends Whats good',\n",
       " 'gon dont moment people na .. since really another around',\n",
       " 'asked people going feel right form person know program day',\n",
       " 'United States Bush America percent dont one plan What American',\n",
       " 'type time understand depressed truly one things last something And',\n",
       " 'restless brotherhood We love tomorrow understanding another world life group',\n",
       " 'President areas reform Japan minister broadband political Arroyo Kazakhstan commitment',\n",
       " 'boy set makes Nights night youll better hope hear theyre',\n",
       " 'March urlLink history like people loyalty Party result well Communist',\n",
       " 'Al held without law new cases knew since weeks measures',\n",
       " 'girl magazine stories big Jelals number identity And since actually',\n",
       " 'Board Conference accounting next company market radio Internet Source economy',\n",
       " 'Christians Jesus time symbolic one symbolically even also form would',\n",
       " 'people dont cool music youve would fun Whats done like',\n",
       " 'might good available get information like community This far paper',\n",
       " 'run know But would Democratic responsibility Times like Bush country',\n",
       " 'nucleus enough Now percent When form In Your Nuclear least',\n",
       " 'attacking lot defense Attacking company defending help following mob defend',\n",
       " 'hands placed long Time sex hot erection pussy becoming time',\n",
       " 'What If future may past lose born one present experiences',\n",
       " 'It Francisco record one people San Fox good News Bill',\n",
       " 'identify helicopters It units create given assets perhaps technologies platforms',\n",
       " 'first hold selectors information address MQBACK form MQSET MQCMIT Queue',\n",
       " 'year find Jade would kill since Orin thing cant Ive',\n",
       " 'information aircraft States month United IAEA long year could Iraqi',\n",
       " 'silent communication fight came information blue columns together coffee large',\n",
       " 'think since another room one friends see prom Thwing day',\n",
       " '... get VI like planets great information understand Saturn If',\n",
       " 'next decided night Matt stop really The since Jodie goodbye',\n",
       " 'heard since plan knew single times us services getting It',\n",
       " 'people understand whole little know uh think right takes nods',\n",
       " 'last The published well short best sold What That It',\n",
       " 'Against love youve A Whats thing done time Im think',\n",
       " 'Jazz im Combo tempo player since last bass dont well',\n",
       " 'person Im people better movie would since could But college',\n",
       " 'place word may always since never idea true Because class',\n",
       " 'would Alana breast pleasure thinking room know since hair one',\n",
       " 'Party feel getting know fish views children free things didnt',\n",
       " 'households large banking small demand loan year provision NABARD formal',\n",
       " 'received report Bronze two third back former according Boston quoted',\n",
       " 'contraception often organizations Teen abstinence community sexually information prevention comprehensive',\n",
       " 'San Ruth Francisco even better could one Left Professor however',\n",
       " 'still money really know What see one look The could',\n",
       " 'Oberlin years crowd former Bermudez San America',\n",
       " 'Soundtrack Original former DArcy would Chicago began tour Chamberlin set',\n",
       " 'looked always What still first dear began husband could thought',\n",
       " 'Party monarch King appointed chief elections border May general international',\n",
       " 'former state made Rosoboronexport official arms complaint states ago countries',\n",
       " 'pizza since whipped ended A food outta started called joD',\n",
       " 'If Be Is Think Want It ... Time Ever How',\n",
       " 'Using x Network Platform Edition Software Express VERITAS File system',\n",
       " 'York us trend As Lynds Wall published book books form',\n",
       " 'Jordan Charles Girls Dickens Stephen King World Time House To',\n",
       " 'Nations Kerry States programs since develop October Oct Iraqs security',\n",
       " 'Against Heather Had This In To love Whats Im done',\n",
       " 'new go time bed since makes like thing And Ill',\n",
       " 'Against love really done .... Whats dont school YOU Not',\n",
       " 'everything girl goes lol hope things Brad web guys dont',\n",
       " 'happy ending kind dont really Nikolai way relationship though Francisco',\n",
       " 'red grade really would If thats first youve Whats go',\n",
       " 'since actually feel might But sure room dont Jane wasnt',\n",
       " 'Been TO last dont though YOU What friends Number see',\n",
       " 'terrorism campaign level many threats hes orange yellow former political',\n",
       " 'people someone first Had Were think sex good Whats white',\n",
       " 'wall lockers first shower know sergeants formation make take hour',\n",
       " 'If Want Is Time Be It Think On Ever Love',\n",
       " 'Have ever Your opposite good phone Whats last believe like',\n",
       " 'fate last Gretchen Moon part since feel used everything night',\n",
       " 'since Day Fathers hes Mikie lost really always park The',\n",
       " 'Iraqis members guards group started school Shiites ever Party outside',\n",
       " 'states detained house feet used information officials behind called crime',\n",
       " 'social acts life form one example approach faith others many',\n",
       " 'didnt make head first day took Miami really us since',\n",
       " 'many shall concerned would fear beliefs understand give mind mediator',\n",
       " 'science new see Joss episode Whedon Serenity crew one time',\n",
       " 'whole took Alex make golden kill managed fired hope anyone',\n",
       " 'must theorists early way significant objects several fact form development',\n",
       " 'Like Is There Dead Im Animals That And Can Times',\n",
       " '... see can something Father not understand feel within front',\n",
       " 'singing forever started terrible time company roseanne boy always every',\n",
       " 'made another understand lot Picasso museum church Dame Paris room',\n",
       " 'By Currently Playing related well April school Sunday crazy since',\n",
       " 'hope bad tell happy Ive time wont youre If ever',\n",
       " 'Performance press see performance connect cost files later icon installed',\n",
       " 'Jess anyone think people last Yasmin Have Whats Buzz name',\n",
       " 'friend since school say ...... new take sleep Kim movie',\n",
       " 'Big measure galaxy thus lines Bang content generation two formation',\n",
       " 'sure one time minutes thats last apartment night She What',\n",
       " 'consumption much supply low part growth informal political cost income',\n",
       " 'Captain Picard know able main Directive need What society among',\n",
       " 'phrases literature subcategory text Medline planning concepts four Information may',\n",
       " 'really quite Sefinas understand realized musical never soul hard words',\n",
       " 'usually hope gave sky sad worse attention start tv LA',\n",
       " 'agent suffix get using names hops since allow bootstrap kernel',\n",
       " 'known Israel Pakistan religion would also What U.S. Iraq',\n",
       " 'last scandal since Swadi abuse first male woman says soldiers',\n",
       " 'higher believe AIDS gays crime understand The If would well',\n",
       " 'hours Carskadon A well problems information study Disorders accidents society',\n",
       " 'BOOK LAUNCH .pm Gang company Victims In London lives Jeppesen',\n",
       " 'haha first Best Tracy movie Whats dont bed people ever',\n",
       " 'capital curriculum next College programs wanted student science people community',\n",
       " 'interested one go get good mushrooms Id What How talking',\n",
       " 'make time dont going world What report us even reading',\n",
       " 'great since one government September Afghanistan media military administration General',\n",
       " 'Ms. California Senate whether process Committee speak information actually administration',\n",
       " 'many river village day vodka thing young since tea looking',\n",
       " 'hope come today someone course right whatever would job much',\n",
       " 'sick lossmaking But company close workers props new spite even',\n",
       " 'Pike government program might DARPA information see cars almost change',\n",
       " 'performance real big first gain economy world since two weeks',\n",
       " 'If know To like What would wrong using make White',\n",
       " 'thing seemed wasnt didnt company licorice getting A mouth project',\n",
       " '... According night nbsp But And Out former',\n",
       " 'RAM Software hard sound work better performance well online look',\n",
       " 'bar might enough since take Daze It returns takes turns',\n",
       " 'even cant things.nbsp much still What feel got thing one',\n",
       " 'talk really never since school Aimee ask life pretty Doran',\n",
       " 'made public results also counting years campaign people hope say',\n",
       " 'Food business markets customer RETAIL Oakley Write performance Tom brands',\n",
       " 'province Median weeks employees coverage patient prices company much cost',\n",
       " 'Party occupation For long conservatives good America religious influence even',\n",
       " 'consumer many make home rise also prices packages information selling',\n",
       " 'abortions life States point forms preventable issue importance single The',\n",
       " 'cases believe since President judge In Judge time My The',\n",
       " 'keep science Once A idea war machines humanity Mond digression',\n",
       " 'Uncle grandmother Frank man mothers uniform though first American California',\n",
       " 'Times great statement establishment issues War social class patriotism administration',\n",
       " 'light brain professors argument see not science can know exist',\n",
       " 'Girls Charles Dickens Jordan World King Time House To Thomas',\n",
       " 'Doctor Chadmon help TO What potential legal free Adam person',\n",
       " 'Times second national told defense package way fertility Congress stocks',\n",
       " 'pitcher Francisco season club may number well innings last It',\n",
       " 'ago Kyle uh um Had thing YOU done Whats love',\n",
       " 'growing trade small terrorism use number since President vulnerable African',\n",
       " 'right came see told go still teachers went since ready',\n",
       " 'lot read thats since name mom kinda song night making',\n",
       " 'context smaller One switching understand Do larger It made excessive',\n",
       " 'since house still knowing song world powers inside cabin six',\n",
       " 'let .... waiting take crying You please ever understand never',\n",
       " 'better lucky since day trying Paul without tell never realize',\n",
       " 'though enough person hope What would believe make well hell',\n",
       " 'Have Things Like color would Best hair What know right',\n",
       " 'gon na drumbone Dustin around since playing fucking go Nicholas',\n",
       " 'argument true properly minors legislative application act exercise since Indeed',\n",
       " 'Jam Nuyorican Caf Poets reading series HBO venues City performing',\n",
       " 'It Is Want If Be Think On Time How Ever',\n",
       " 'upon since Sparta makes Ajax times knows away tells Hollywood',\n",
       " 'Lite banners Smith company secular Channel covered MWSmith person trying',\n",
       " 'Platform Greens Senator administration Sen. U.S. Kerrys As change war',\n",
       " 'Francisco husband real woman character Bay books life Black first',\n",
       " 'poll Pew Britain Spain last since summer In world Americans',\n",
       " 'hope inside know thought eyes must You Ive go Dont',\n",
       " 'Republican Washington may Convention National former George surprises October little',\n",
       " 'world order reformist Iranian clergies one years last reformists Iraq',\n",
       " 'Best anything hair cant Have B Im arm What best']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(df, model, df.title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f6c9050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geometry idea cant th something May Biology went Latin still',\n",
       " 'His table thoughts front group Well hour life noticed day',\n",
       " 'church fact first Detective close enough looked made two front',\n",
       " 'power would George big West Wing Washington thing fact mean',\n",
       " 'new In fact good favorite remember say school decade time',\n",
       " 'great world thing little even In play guys fact President',\n",
       " 'home stuff left Kinker came group room people time much',\n",
       " 'time trying people although know say hes fact first friend',\n",
       " 'restless brotherhood We love tomorrow understanding another world life group',\n",
       " 'boy set makes Nights night youll better hope hear theyre',\n",
       " 'March urlLink history like people loyalty Party result well Communist',\n",
       " 'idea misunderstood free debate double burden dialoguing Ive But make',\n",
       " 'TypeI breakfast dinner every diabetic control component wasnt read fact',\n",
       " 'including Uighur international Xinjiang groups torture Tibetan Uygur Falun year',\n",
       " 'might good available get information like community This far paper',\n",
       " 'drag youre theyre way public general get Ill But believe',\n",
       " 'values group associate happy higher gave family might dont She',\n",
       " 'paper diversity much case Qaeda would one issue said course',\n",
       " 'fact room home long asked back girlfriend weekend couldnt phone',\n",
       " 'fact way ...... anyone things still well within see sighs',\n",
       " 'even first looking well get holidays relationship years getting article',\n",
       " 'protect lived one boyfriend least first line County died told',\n",
       " 'phone pick meet home way things go people could relationship',\n",
       " 'It Francisco record one people San Fox good News Bill',\n",
       " 'Christian quite get newspaper isnt ever anyone author think immigrants',\n",
       " 'airport first pizza bed leave Friday work one wouldnt fact',\n",
       " 'Boston published Sontag fact big felt new kind York essays',\n",
       " 'issue never said sexually The see relationship much one In',\n",
       " 'earth can would ideas lines people not air building light',\n",
       " 'n general development record studies disease cardiovascular outcomes systems available',\n",
       " 'may individual individuals groups also well within rather If wolf',\n",
       " 'soccer betting say im relationship think film tries guy girl',\n",
       " 'required This time known discovered paper Daguerreotype much images Nipce',\n",
       " 'might whole long village never fact seen Yes strange made',\n",
       " 'How ideal time attracted partner sex The make man test',\n",
       " 'right interests always Animals reason others factory laboratories There suffer',\n",
       " 'novel Dr. good Uyterhoeven would vision life write reader idea',\n",
       " 'taking Ministry Romanian institutions Saddam open fact based people Romania',\n",
       " 'place word may always since never idea true Because class',\n",
       " 'thing strange like long though even well paperboats part much',\n",
       " 'strip Saturday club Diego group clubs least November owner By',\n",
       " 'relationship ... sexual one much statistics Samuel know homosexual fact',\n",
       " 'even would used didnt years way fact care head thing',\n",
       " 'Party feel getting know fish views children free things didnt',\n",
       " 'San Ruth Francisco even better could one Left Professor however',\n",
       " 'one say Alister new John time piece group album week',\n",
       " 'Party monarch King appointed chief elections border May general international',\n",
       " 'unions couples If many legal civil even rights It relationships',\n",
       " 'not can meaning general sexuality Leviticus important two passages focus',\n",
       " 'would Knox past music record Chris Shepherd But sound group',\n",
       " 'knew The war used paper made guess even U.S. drug',\n",
       " 'Israels In policy This War Gulf Ostrovsky campaign Israelis fact',\n",
       " 'questions Heloises words relationship even love share use',\n",
       " 'come Sunday life good week deep relationships something live know',\n",
       " 'Operations Command Base strategic lines command terrorist AC general many',\n",
       " 'specialized European recent almost projects group one city In society',\n",
       " 'happy ending kind dont really Nikolai way relationship though Francisco',\n",
       " 'world years Gulja time many terrorist could majority groups people',\n",
       " 'Dr. handle Phillips assignments group willing one well year would',\n",
       " 'concept The could war made became ideas mathematical electronic Alan',\n",
       " 'not Agnostics The think can cant going stop government fact',\n",
       " 'GB separate add filegroups per tables important file order make',\n",
       " 'temple American take lunch took On group Erin would first',\n",
       " 'NOT thing best great decide fact actually next go dont',\n",
       " 'Iraqis members guards group started school Shiites ever Party outside',\n",
       " 'dont shows behind Show Leno television fact never days seen',\n",
       " 'things go less would actually general even time ex thought',\n",
       " 'science new see Joss episode Whedon Serenity crew one time',\n",
       " 'must theorists early way significant objects several fact form development',\n",
       " 'singing forever started terrible time company roseanne boy always every',\n",
       " 'course time She fact Its us get idiocy biggest America',\n",
       " 'THE know boy nbsp LAST get If Been one really',\n",
       " 'may says book say used way gross feel like fact',\n",
       " 'require enjoy tend idealistic physical new may try dont get',\n",
       " 'man .... religious world become Christian began issue relationship BLACK',\n",
       " 'In another people relationship The aids year think back said',\n",
       " 'relationship someone even loss become else circumstantial isnt real actually',\n",
       " '... place Daddy made make People school drugs father group',\n",
       " 'led ruling Chhatra independence elections became fact In Hasina Sheikh',\n",
       " 'tho idea sum CONGRATULATIONS confused paul fun good worry lot',\n",
       " 'vote rights groups smiths individual demand says keep tax know',\n",
       " 'analysis objective possible relationship family make true personal draft able',\n",
       " 'capital curriculum next College programs wanted student science people community',\n",
       " 'Why long How told flinch away know relationship day sitting',\n",
       " 'room told good boys When piano went We It wanted',\n",
       " 'Pan group leadership Turkic accept provide Islamic within people It',\n",
       " 'Forum Lives employment dads Families Childrens general include noted commitment',\n",
       " 'tavern letters one general angrily room nothing letter woman daughter',\n",
       " 'much propositions illusion fact mode can not This upon say',\n",
       " 'chairman beauty officer health .pc development Boots group services Europe',\n",
       " 'thing .... Westminster see fact people yet You sure may',\n",
       " 'think wasnt fellow competition fact maybe give three chair old',\n",
       " 'fact world think heterosexual people right back urlLink even us',\n",
       " 'think take The us get wasnt He home said group',\n",
       " 'like fact good Contemporary coercive way Community argue means theory',\n",
       " 'real fact hood boy rap many guy music shit They',\n",
       " 'really let wont right football times like fact And home',\n",
       " 'federal groups years would diabetes issue state Alzheimers says measure',\n",
       " 'never fact school would life though need hate work The',\n",
       " 'Party occupation For long conservatives good America religious influence even',\n",
       " 'camp behind guide alone headlamps way could groups without ice',\n",
       " 'one said motive You person talk make like course facts',\n",
       " 'home TV bad lot little boys see dogs Mom If',\n",
       " 'Gerene license according influence newspaper files After mother revoked sentence',\n",
       " 'kind Steve get one boyfriend guy little good even believe',\n",
       " 'keep science Once A idea war machines humanity Mond digression',\n",
       " 'light brain professors argument see not science can know exist',\n",
       " 'new try When mate idealistic sensual physical passionate important relationship',\n",
       " 'shit never buy history get fact rights take So tired',\n",
       " 'aimed War Bush An behind hawks Gulf idea whole set',\n",
       " 'pitcher Francisco season club may number well innings last It',\n",
       " 'anything centre Now And He fact says many conversation man',\n",
       " 'even way still relationship started got came balcony wasnt Saturday',\n",
       " 'mounted horses slope huts archers king hobilars one group horse',\n",
       " 'ended girl hard come always Texas fact around remember tell',\n",
       " 'good kid soon even school nurse among could fact love',\n",
       " 'Jamiels got old biological get new child little phone fact',\n",
       " 'story fact w one said back called Ok got couldnt',\n",
       " 'need study medium boys words able student excellent potential taught',\n",
       " 'would person History anything know paper book Ive someone If',\n",
       " 'th This majority Christians Dolui South group person',\n",
       " 'time fact question would band one music group Life',\n",
       " 'animals Clear like Channel intelligence U.S. get fact people money',\n",
       " 'human passage people Jesus use general Fichte published Rosenbergs part',\n",
       " 'Francisco husband real woman character Bay books life Black first',\n",
       " 'blond way boy drink drunk walking isnt look My Rose',\n",
       " 'didnt need well time group say exhibition taekwondo much sign']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(df, model, 'my new sentence')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
